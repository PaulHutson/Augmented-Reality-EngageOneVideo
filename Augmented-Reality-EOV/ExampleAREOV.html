<!DOCTYPE html>
<meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
<!-- three.js library -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/three.js/91/three.min.js'></script>
<!-- ar.js -->
<script src="https://jeromeetienne.github.io/AR.js/three.js/build/ar.js"></script>
<
<script>THREEx.ArToolkitContext.baseURL = 'https://jeromeetienne.github.io/AR.js/'</script>

<video id="myVideo" autoplay style="display:none;">
    <source src="Video/sintel.ogv" type='video/ogg; codecs="theora, vorbis"'>
</video>

<body style='margin : 0px; overflow: hidden; font-family: Monospace;'>
    <script>
	//////////////////////////////////////////////////////////////////////////////////
	//		Init
	//////////////////////////////////////////////////////////////////////////////////
	// init renderer
	var renderer	= new THREE.WebGLRenderer({
		antialias: true,
		alpha: true
	});
	renderer.setClearColor(new THREE.Color('lightgrey'), 0)
	renderer.setSize( 640, 480 );
	renderer.domElement.style.position = 'absolute'
	renderer.domElement.style.top = '0px'
	renderer.domElement.style.left = '0px'
	document.body.appendChild( renderer.domElement );
	// array of functions for the rendering loop
	var onRenderFcts= [];
	// init scene and camera
	var scene	= new THREE.Scene();

	//////////////////////////////////////////////////////////////////////////////////
	//		Initialize a basic camera
	//////////////////////////////////////////////////////////////////////////////////
	// Create a camera
	var camera = new THREE.Camera();
	scene.add(camera);
	////////////////////////////////////////////////////////////////////////////////
	//          handle arToolkitSource
	////////////////////////////////////////////////////////////////////////////////
	var arToolkitSource = new THREEx.ArToolkitSource({
		// to read from the webcam
		sourceType : 'webcam',

		// // to read from an image
		// sourceType : 'image',
		// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/images/img.jpg',
		// to read from a video
		// sourceType : 'video',
		// sourceUrl : THREEx.ArToolkitContext.baseURL + '../data/videos/headtracking.mp4',
	})
	arToolkitSource.init(function onReady(){
		onResize()
	})

	// handle resize
	window.addEventListener('resize', function(){
		onResize()
	})
	function onResize(){
		arToolkitSource.onResize()
		arToolkitSource.copySizeTo(renderer.domElement)
		if( arToolkitContext.arController !== null ){
			arToolkitSource.copySizeTo(arToolkitContext.arController.canvas)
		}
	}
	////////////////////////////////////////////////////////////////////////////////
	//          initialize arToolkitContext
	////////////////////////////////////////////////////////////////////////////////

	// create atToolkitContext
	var arToolkitContext = new THREEx.ArToolkitContext({
	    cameraParametersUrl: 'https://jeromeetienne.github.io/AR.js/data/data/camera_para.dat',
		detectionMode: 'mono',
	})
	// initialize it
	arToolkitContext.init(function onCompleted(){
		// copy projection matrix to camera
		camera.projectionMatrix.copy( arToolkitContext.getProjectionMatrix() );
	})
	// update artoolkit on every frame
	onRenderFcts.push(function(){
		if( arToolkitSource.ready === false )	return
		arToolkitContext.update( arToolkitSource.domElement )

		// update scene.visible if the marker is seen
		scene.visible = camera.visible
	})

	////////////////////////////////////////////////////////////////////////////////
	//          Create a ArMarkerControls
	////////////////////////////////////////////////////////////////////////////////

	// init controls for camera
	var markerControls = new THREEx.ArMarkerControls(arToolkitContext, camera, {
		type : 'pattern',
		patternUrl: 'https://jeromeetienne.github.io/AR.js/data/data/patt.hiro',
		// patternUrl : THREEx.ArToolkitContext.baseURL + '../data/data/patt.kanji',
		// as we controls the camera, set changeMatrixMode: 'cameraTransformMatrix'
		changeMatrixMode: 'cameraTransformMatrix'
	})
	// as we do changeMatrixMode: 'cameraTransformMatrix', start with invisible scene
	scene.visible = false




	///////////
	// VIDEO //
	///////////

	// create the video element
	video = document.getElementById('myVideo');

	videoImage = document.createElement('canvas');
	videoImage.width = 480;
	videoImage.height = 204;

	videoImageContext = videoImage.getContext('2d');
	//// background color if no video present
	videoImageContext.fillStyle = '#000000';
	videoImageContext.fillRect(0, 0, videoImage.width, videoImage.height);

	videoTexture = new THREE.Texture(videoImage);
	videoTexture.minFilter = THREE.LinearFilter;
	videoTexture.magFilter = THREE.LinearFilter;

	var movieMaterial = new THREE.MeshBasicMaterial({ map: videoTexture, overdraw: false, side: THREE.DoubleSide, color: 0x777777 });
	//var movieMaterial = new THREE.MeshBasicMaterial({ color: 0x777777 });
	//// the geometry on which the movie will be displayed;
	//// 		movie image will be scaled to fit these dimensions.
	var movieGeometry = new THREE.PlaneGeometry(240, 100, 4, 4);
	var movieScreen = new THREE.Mesh(movieGeometry, movieMaterial);
	movieScreen.position.y = movieGeometry.parameters.height / 2;
	//scene.add(movieScreen);



	//////////////////////////////////////////////////////////////////////////////////
	//		add an object in the scene
	//////////////////////////////////////////////////////////////////////////////////
	var geometry	= new THREE.CubeGeometry(2.4,0.1,1);
	//var material	= new THREE.MeshNormalMaterial({
	//	transparent : true,
	//	opacity: 0.5,
	//	side: THREE.DoubleSide
        //});
	var material = new THREE.MeshBasicMaterial({ map: videoTexture, overdraw: false, side: THREE.DoubleSide, color: 0x777777 });
	var mesh	= new THREE.Mesh( geometry, material );
	mesh.position.y	= geometry.parameters.height/2
	scene.add( mesh );


	//////////////////////////////////////////////////////////////////////////////////
	//		render the whole thing on the page
	//////////////////////////////////////////////////////////////////////////////////
	// render the scene
	onRenderFcts.push(function(){
		renderer.render( scene, camera );
	})
	// run the rendering loop
	var lastTimeMsec= null
	requestAnimationFrame(function animate(nowMsec) {
	    if (video.readyState === video.HAVE_ENOUGH_DATA) {
	        videoImageContext.drawImage(video, 0, 0);
	        if (videoTexture)
	            videoTexture.needsUpdate = true;
	    }

		// keep looping
		requestAnimationFrame( animate );
		// measure time
		lastTimeMsec	= lastTimeMsec || nowMsec-1000/60
		var deltaMsec	= Math.min(200, nowMsec - lastTimeMsec)
		lastTimeMsec	= nowMsec
		// call each update function
		onRenderFcts.forEach(function(onRenderFct){
			onRenderFct(deltaMsec/1000, nowMsec/1000)
		})
	})
    </script>
</body>